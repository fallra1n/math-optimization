{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d55e1829",
      "metadata": {},
      "source": [
        "# Project2\n",
        "Новак Евгений <br>\n",
        "Орлов Григорий <br>\n",
        "Тожимухаммедов Асадбек <br>\n",
        "Вариант: 1\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74608881",
      "metadata": {},
      "source": [
        "## Условие: <br>\n",
        "* **Реализовать метод наискорейшего спуска (золотое сечение), метод Левенберга-Марквартда**<br>\n",
        "\n",
        "* **Тестовые функции**\n",
        "\n",
        "1. Расчет минимума сильно-выпуклой функции:\n",
        "\t\t$$\n",
        "\t\tf(x) = \\frac{L - \\mu}{8} \\left[ x_1^2 + \\sum_{i=2}^n (x_i - x_{i+1})^2 - 2x_1 \\right] + \\frac{\\mu}{2} \\| x \\|_2^2\n",
        "\t\t$$\n",
        "\t\tПолагаем $ L = 100, \\mu = 0.1 $.\n",
        "\n",
        "2. Расчет двойственной задачи к задаче расчета матрицы корреспонденций:\n",
        "\t\t$$\n",
        "\t\tf(x, y) = -(L, x) - (W, y) + \\ln \\left[ \\sum_{i,j} \\exp(-\\alpha c_{ij} + x_i + y_j) \\right]\n",
        "\t\t$$  \n",
        "\t\tЗдесь: $ x \\in R^n, \\, y \\in R^n, \\, L, W \\in R_{+}^n, \\, \\| L \\|_1 = 1, \\, \\| W \\|_1 = 1, \\, \\alpha \\geq 1, \\, c_{ij} \\in [0, 1] $. Параметры $ L, W, c $ задаются случайно, $ \\alpha = 100 $.\n",
        "\n",
        "3. Функция Розенброка ($ x \\in R^n, \\, x^* \\equiv 1_n, \\, f^* = 0 $):  \n",
        "\t\t$$\n",
        "\t\tf(x) = (x_1 - 1)^2 + \\alpha \\sum_{i=2}^n (x_i - x_{i-1}^2)^2.\n",
        "\t\t$$  \n",
        "\t\tПараметр $ \\alpha $ можно варьировать. Для тестов возьмем его 10.\n",
        "\n",
        "4. Задача энтропийно-линейного программирования без ограничений:\n",
        "\t\t$$\n",
        "\t\tf(x) = \\sum_{i=1}^n x_i \\ln \\frac{x_i}{\\xi_i}, \\, x \\in R_{+}^n; \\, (n = 10, \\ldots 1000); \\, \\xi_i = 1/i\n",
        "\t\t$$\n",
        "\n",
        "5. Линейная регрессия:\n",
        "\t\t$$\n",
        "\t\tf(x) = \\sum_{i=1}^m ((a^i, x) - b_i)^2\n",
        "\t\t$$  \n",
        "\t\tПараметр $ m = 100, \\, $ значения $ a^i \\in R^n, \\, b_i $ выбираются случайно.\n",
        "\n",
        "6. Функция правдоподобия:\n",
        "\t\t$$\n",
        "\t\tf(x,y) = -\\sum_{i=1}^{k}(x^T a^i + y) + \\sum_{i=1}^{m}\\ln(1 + \\exp(x^T a^i + y))\n",
        "\t\t$$\n",
        "\n",
        "* **Комментарии**\n",
        "\n",
        "1. Начальная точка выбирается случайно на достаточно большом удалении от оптимальной точки. Расстояние фиксируется одним и тем же для разных размерностей задачи.  \n",
        "2. Точность решения варьируется от $10^{-4}$ до $10^{-5}$ с шагом $10^{-5}$.  \n",
        "3. Точность одномерного поиска варьируется от $10^{-7}$ до $10^{-8}$ с шагом $10^{-8}$.  \n",
        "4. Размерность задачи варьируется: 10, 20, 30, 40, 50, 60, 60, 70, 80, 90, 100, 200, 400, 600, 800, 1000.  \n",
        "\n",
        "* **Графики**\n",
        "\n",
        "1. Для фиксированных выбранных значений точности одномерного поиска и точности решения задачи по функции построить график зависимости времени решения от размерности задачи.  \n",
        "2. Для фиксированных выбранных значений размерности задачи и точности одномерного поиска построить график зависимости времени решения задачи от требуемой точности решения задачи по функции.  \n",
        "3. Для фиксированных выбранных значений размерности и точности решения задачи по функции построить график зависимости времени решения от точности одномерного поиска.  \n",
        "4. Для фиксированных выбранных значений точности одномерного поиска, размерности задачи и точности решения задачи по функции построить график зависимости времени решения от расстояния между начальной точкой и оптимальной точкой.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3651ba7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import autograd.numpy as agnp\n",
        "import numpy as np\n",
        "import autograd as ag\n",
        "import copy\n",
        "from typing import Callable\n",
        "from typing import Dict, Any, Tuple\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d42eebc9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Метод золотого сечения из прошлого проекта\n",
        "\n",
        "\n",
        "def golden_section_search(\n",
        "    f: Callable[[float, agnp.ndarray], float], a: float, b: float, d: agnp.ndarray, eps: float\n",
        ") -> tuple[float, list, list, int]:\n",
        "    phi = (1 + np.sqrt(5)) / 2\n",
        "    x1 = a + (b - a) / (phi + 1)\n",
        "    x2 = b - (b - a) / (phi + 1)\n",
        "    f1, f2 = f(x1, d), f(x2, d)\n",
        "\n",
        "    iter_num, lst_x, lst_y = 0, [], []\n",
        "    lst_x.append(0)\n",
        "    lst_y.append((a + b) / 2)\n",
        "\n",
        "    while abs(b - a) > eps:\n",
        "        iter_num += 1\n",
        "        if f1 < f2:\n",
        "            b = x2\n",
        "            x2, f2 = x1, f1\n",
        "            x1 = a + (b - a) / (phi + 1)\n",
        "            f1 = f(x1, d)\n",
        "        else:\n",
        "            a = x1\n",
        "            x1, f1 = x2, f2\n",
        "            x2 = b - (b - a) / (phi + 1)\n",
        "            f2 = f(x2, d)\n",
        "\n",
        "        lst_x.append(iter_num)\n",
        "        lst_y.append((a + b) / 2)\n",
        "    return ((a + b) / 2, copy.deepcopy(lst_x), copy.deepcopy(lst_y), iter_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e56a6658",
      "metadata": {},
      "outputs": [],
      "source": [
        "eps_fastest = 10 ** (-4)\n",
        "eps_golden = 10 ** (-7)\n",
        "\n",
        "\n",
        "def the_fastest_descent(\n",
        "    f: Callable[[agnp.ndarray, Dict[str, Any]], float],\n",
        "    param_list: Dict[str, Any],\n",
        "    x0: agnp.ndarray,\n",
        "    max_steps: int,\n",
        "    eps: float,\n",
        ") -> Tuple[agnp.ndarray, ...]:\n",
        "    x_old = agnp.copy(x0)\n",
        "\n",
        "    def func_of_h(h: float, d: agnp.ndarray) -> float:\n",
        "        return f(x_old + h * d, param_list)\n",
        "\n",
        "    def localize_minimum(\n",
        "        func_of_h: Callable[[float, agnp.ndarray], float], d: agnp.ndarray, h=10 ** (-2), max_iter=100, growth_factor=2\n",
        "    ):\n",
        "\n",
        "        a = 0\n",
        "        b = h\n",
        "        f_a = func_of_h(a, d)\n",
        "        f_b = func_of_h(b, d)\n",
        "\n",
        "        if f_b >= f_a:\n",
        "            return a, b\n",
        "\n",
        "        c = b * growth_factor\n",
        "        f_c = func_of_h(c, d)\n",
        "        if f_c >= f_a:\n",
        "            return a, c\n",
        "\n",
        "        while f_c < f_a and max_iter >= 1:\n",
        "            max_iter -= 1\n",
        "            a = b\n",
        "            b = c\n",
        "            c = c * growth_factor\n",
        "            f_a = f_b\n",
        "            f_b = f_c\n",
        "            f_c = func_of_h(c, d)\n",
        "            if f_c >= f_a:\n",
        "                return a, c\n",
        "\n",
        "        return a, c\n",
        "\n",
        "    x_new = x_old\n",
        "    d = -ag.grad(f, argnum=0)(x_old, param_list)  # -numerical_gradient(f, x0)\n",
        "    while agnp.linalg.norm(d) ** 2 > eps and max_steps > 0:\n",
        "        max_steps -= 1\n",
        "\n",
        "        a, b = localize_minimum(func_of_h, d)\n",
        "        x_new = x_old + (golden_section_search(func_of_h, a, b, d, eps_golden)[0]) * d\n",
        "        d = -ag.grad(f, argnum=0)(x_new, param_list)\n",
        "        x_old = agnp.copy(x_new)\n",
        "\n",
        "    return x_new\n",
        "\n",
        "\n",
        "def quadratic1d(x: agnp.ndarray, param_list: Dict[str, Any]) -> float:\n",
        "    return x[0] ** 2 + x[1] ** 2 + x[2] ** 2\n",
        "\n",
        "\n",
        "param_list, x0, max_steps, eps = {}, agnp.array([1.0, 0.9, -1]), 100, 1e-6\n",
        "result = the_fastest_descent(quadratic1d, param_list, x0, max_steps, eps)\n",
        "print(\"Quadratic1d:\", result)  # Ожидается ~[(0, 0, 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "506baf12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# levenberg_markvatd\n",
        "\n",
        "\n",
        "def hessian(func, x: np.ndarray):\n",
        "    return ag.jacobian(ag.grad(func))(x)\n",
        "\n",
        "\n",
        "def levenberg_markvatd2(\n",
        "    f: Callable[[agnp.ndarray, Dict[str, Any]], float],\n",
        "    param_list: Dict[str, Any],\n",
        "    x0: agnp.ndarray,\n",
        "    max_steps: int,\n",
        "    eps: float,\n",
        ") -> Tuple[agnp.ndarray, ...]:\n",
        "    alpha = 10**4\n",
        "    x_old = agnp.copy(x0)\n",
        "    x_len = len(x_old)\n",
        "\n",
        "    for _ in range(max_steps):\n",
        "        grad_f = ag.grad(f, argnum=0)(x_old, param_list)\n",
        "        if agnp.linalg.norm(grad_f) < eps:\n",
        "            return x_old\n",
        "\n",
        "        H = hessian(lambda args: f(args, param_list), x_old)\n",
        "\n",
        "        while True:\n",
        "            sk = agnp.linalg.inv(H + alpha * agnp.eye(x_len)) @ grad_f\n",
        "            x_new = agnp.copy(x_old - sk)\n",
        "            if f(x_new, param_list) < f(x_old, param_list):\n",
        "                alpha /= 2\n",
        "                break\n",
        "            else:\n",
        "                alpha *= 2\n",
        "\n",
        "        x_old = agnp.copy(x_new)\n",
        "\n",
        "    return x_new\n",
        "\n",
        "\n",
        "def quadratic1d(x: agnp.ndarray, param_list: Dict[str, Any]) -> float:\n",
        "    return x[0] ** 2 + x[1] ** 2 + x[2] ** 2\n",
        "\n",
        "\n",
        "param_list, x0, max_steps, eps = {}, agnp.array([1.0, 0.9, -1]), 100, 1e-6\n",
        "result = levenberg_markvatd2(quadratic1d, param_list, x0, max_steps, eps)\n",
        "print(\"Quadratic1d:\", result)  # Ожидается ~[(0, 0, 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebde87fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# test funcs\n",
        "# сигнатура: (args: , param_list: Dict[str, Any])\n",
        "\n",
        "\n",
        "# Сильно-выпуклая функция\n",
        "def strongly_convex(x: agnp.ndarray, param_list: Dict[str, Any]) -> float:\n",
        "    L, mu = param_list[\"L\"], param_list[\"mu\"]\n",
        "    return ((L - mu) / 8) * (x[0] ** 2 + agnp.sum((x[:-1] - x[1:]) ** 2) - 2 * x[0]) + (mu / 2) * agnp.linalg.norm(\n",
        "        x\n",
        "    ) ** 2\n",
        "\n",
        "\n",
        "# Двойственная задача матрицы корреспонденций\n",
        "def dual_correspondence(\n",
        "    x: agnp.ndarray,\n",
        "    param_list: Dict[str, Any],\n",
        ") -> float:\n",
        "    x0 = x[: len(x) // 2]\n",
        "    y0 = x[len(x) // 2 :]\n",
        "    L, W, c = param_list[\"L\"], param_list[\"W\"], param_list[\"c\"]\n",
        "    return -agnp.dot(L, x0) - agnp.dot(W, y0) + agnp.log(agnp.sum(agnp.exp(-100 * c + x0[:, None] + y0[None, :])))\n",
        "\n",
        "\n",
        "# Функция Розенброка\n",
        "def rosenbrock(x: agnp.ndarray, param_list: Dict[str, Any]) -> float:\n",
        "    alpha_rosenbrock = param_list[\"alpha_rosenbrock\"]\n",
        "    return (x[0] - 1) ** 2 + alpha_rosenbrock * agnp.sum((x[1:] - x[:-1] ** 2) ** 2)\n",
        "\n",
        "\n",
        "# Энтропийно-линейная функция\n",
        "def entropy_linear(x: agnp.ndarray, param_list: Dict[str, Any]) -> float:\n",
        "    xi = param_list[\"xi\"]\n",
        "    return agnp.sum(x * agnp.log(x / xi))\n",
        "\n",
        "\n",
        "# Линейная регрессия\n",
        "def linear_regression(x: agnp.ndarray, param_list: Dict[str, Any]) -> float:\n",
        "    A, b = param_list[\"A\"], param_list[\"b\"]\n",
        "    return agnp.sum((A @ x - b) ** 2)\n",
        "\n",
        "\n",
        "# Функция правдоподобия\n",
        "def likelihood_function(x: agnp.ndarray, param_list: Dict[str, Any]) -> float:\n",
        "    x0 = x[:-1]\n",
        "    y = x[len(x) - 1]\n",
        "    A = param_list[\"A\"]\n",
        "    bias = y * agnp.ones((A.shape[0],))\n",
        "    linear_term = A @ x0 + bias\n",
        "    return -agnp.sum(linear_term) + agnp.sum(agnp.log(1 + agnp.exp(linear_term)))\n",
        "\n",
        "\n",
        "function_list = [\n",
        "    strongly_convex,\n",
        "    dual_correspondence,\n",
        "    rosenbrock,\n",
        "    entropy_linear,\n",
        "    linear_regression,\n",
        "    likelihood_function,\n",
        "]\n",
        "\n",
        "func_name_list = [\n",
        "    \"StronglyConvex\",\n",
        "    \"DualCorrespondence\",\n",
        "    \"Rosenbrock\",\n",
        "    \"EntropyLinear\",\n",
        "    \"LinearRegression\",\n",
        "    \"LikelihoodFunction\",\n",
        "]\n",
        "\n",
        "dimemsions = [10, 20, 30, 40, 50, 60, 60, 70, 80, 90, 100, 200, 400, 600, 800, 1000]\n",
        "golden_section_accuracies = np.linspace(10 ** (-8), 10 ** (-7), 10)\n",
        "\n",
        "number_of_func = 6\n",
        "\n",
        "\n",
        "# Пример для StronglyConvex\n",
        "def param_gen_1(n):\n",
        "    x = agnp.random.uniform(-1, 1, size=n)\n",
        "    param_list = {\"L\": 100, \"mu\": 0.1}\n",
        "    return (x, param_list)\n",
        "\n",
        "\n",
        "def param_gen_2(n):\n",
        "    x = agnp.random.uniform(-1, 1, size=n)\n",
        "    y = agnp.random.uniform(-1, 1, size=n)\n",
        "    L = agnp.abs(agnp.random.rand(n))\n",
        "    W = agnp.abs(agnp.random.rand(n))\n",
        "    L /= agnp.sum(L)\n",
        "    W /= agnp.sum(W)\n",
        "    c = agnp.random.rand(n, n)\n",
        "    param_list = {\"L\": L, \"W\": W, \"c\": c}\n",
        "    return (agnp.concatenate((x, y)), param_list)\n",
        "\n",
        "\n",
        "def param_gen_3(n):\n",
        "    x = agnp.random.uniform(-1, 1, size=n)\n",
        "    param_list = {\"alpha_rosenbrock\": 100}\n",
        "    return (x, param_list)\n",
        "\n",
        "\n",
        "def param_gen_4(n):\n",
        "    x = agnp.abs(agnp.random.uniform(-1, 1, size=n))  # Должно быть положительным\n",
        "    param_list = {\"xi\": 1 / agnp.arange(1, n + 1)}\n",
        "    return (x, param_list)\n",
        "\n",
        "\n",
        "def param_gen_5(n):\n",
        "    m = 100\n",
        "    x = agnp.random.uniform(-1, 1, size=n)\n",
        "    A = agnp.random.uniform(low=-1, high=1, size=(m, n))\n",
        "    b = agnp.random.uniform(-1, 1, size=m)\n",
        "    param_list = {\"A\": A, \"b\": b}\n",
        "    return (x, param_list)\n",
        "\n",
        "\n",
        "def param_gen_6(n):\n",
        "    m = 100\n",
        "    x = agnp.random.uniform(-1, 1, size=n)\n",
        "    y = agnp.random.uniform(-1, 1, size=1)\n",
        "    A = agnp.random.uniform(low=-1, high=1, size=(m, n))\n",
        "    param_list = {\"A\": A}\n",
        "    return (agnp.concatenate((x, y)), param_list)\n",
        "\n",
        "\n",
        "param_gen = [param_gen_1, param_gen_2, param_gen_3, param_gen_4, param_gen_5, param_gen_6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bc589d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# run on test funcs\n",
        "\n",
        "# запуск на StronglyConvex\n",
        "n = 1\n",
        "x0, param_list = param_gen[0](n)\n",
        "max_steps, eps = 1000, 1e-5\n",
        "result1 = levenberg_markvatd2(strongly_convex, param_list, x0, max_steps, eps)\n",
        "result2 = the_fastest_descent(strongly_convex, param_list, x0, max_steps, eps)\n",
        "print(\"StronglyConvex:\", result1, result2)\n",
        "\n",
        "\n",
        "# запуск на DualCorrespondence\n",
        "n = 2\n",
        "x0, param_list = param_gen[1](n)\n",
        "max_steps, eps = 1000, 1e-5\n",
        "result1 = levenberg_markvatd2(dual_correspondence, param_list, x0, max_steps, eps)\n",
        "result2 = the_fastest_descent(dual_correspondence, param_list, x0, max_steps, eps)\n",
        "print(\"DualCorrespondence:\", result1, result2)\n",
        "\n",
        "# запуск на Rosenbrock\n",
        "n = 15\n",
        "x0, param_list = param_gen[2](n)\n",
        "max_steps, eps = 1000, 1e-12\n",
        "result1 = levenberg_markvatd2(rosenbrock, param_list, x0, max_steps, eps)\n",
        "result2 = the_fastest_descent(rosenbrock, param_list, x0, max_steps, eps)\n",
        "print(\"Rosenbrock:\", result1, result2)\n",
        "\n",
        "# запуск на EntropyLinear\n",
        "n = 5\n",
        "x0, param_list = param_gen[3](n)\n",
        "max_steps, eps = 1000, 1e-5\n",
        "result1 = levenberg_markvatd2(entropy_linear, param_list, x0, max_steps, eps)\n",
        "result2 = the_fastest_descent(entropy_linear, param_list, x0, max_steps, eps)\n",
        "print(\"EntropyLinear:\", result1, result2)\n",
        "\n",
        "\n",
        "# запуск на LinearRegression\n",
        "n = 6\n",
        "x0, param_list = param_gen[4](n)\n",
        "max_steps, eps = 1000, 1e-5\n",
        "result1 = levenberg_markvatd2(linear_regression, param_list, x0, max_steps, eps)\n",
        "result2 = the_fastest_descent(linear_regression, param_list, x0, max_steps, eps)\n",
        "print(\"LinearRegression:\", result1, result2)\n",
        "\n",
        "# запуск на LikelihoodFunction\n",
        "n = 5\n",
        "x0, param_list = param_gen[5](n)\n",
        "max_steps, eps = 1000, 1e-5\n",
        "result1 = levenberg_markvatd2(likelihood_function, param_list, x0, max_steps, eps)\n",
        "result2 = the_fastest_descent(likelihood_function, param_list, x0, max_steps, eps)\n",
        "print(\"LikelihoodFunction:\", result1, result2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5524655",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(21, 14))  # figsize=(ширина, высота)\n",
        "plt.tight_layout(pad=8.0)\n",
        "\n",
        "prec = 1e-5\n",
        "steps = 100000\n",
        "\n",
        "Lst_y_lev = []\n",
        "Lst_x_lev = []\n",
        "Lst_y_fast = []\n",
        "Lst_x_fast = []\n",
        "\n",
        "for i in range(number_of_func):\n",
        "    Lst_y_lev.append([])\n",
        "    Lst_y_fast.append([])\n",
        "    Lst_x_lev.append([])\n",
        "    Lst_x_fast.append([])\n",
        "    for dim in dimemsions:\n",
        "        start_time = time.time()\n",
        "        x0, param_list = param_gen[i](dim)\n",
        "        max_steps, eps = steps, prec\n",
        "        result = levenberg_markvatd2(function_list[i], param_list, x0, max_steps, eps)\n",
        "        end_time = time.time()\n",
        "        Lst_x_lev[i].append(dim)\n",
        "        Lst_y_lev[i].append(end_time - start_time)\n",
        "        if end_time - start_time > 10:\n",
        "            break\n",
        "\n",
        "for i in range(number_of_func):\n",
        "    Lst_y_lev.append([])\n",
        "    Lst_y_fast.append([])\n",
        "    Lst_x_lev.append([])\n",
        "    Lst_x_fast.append([])\n",
        "    for dim in dimemsions:\n",
        "        start_time = time.time()\n",
        "        x0, param_list = param_gen[i](dim)\n",
        "        max_steps, eps = steps, prec\n",
        "        result = the_fastest_descent(function_list[i], param_list, x0, max_steps, eps)\n",
        "        end_time = time.time()\n",
        "        Lst_x_fast[i].append(dim)\n",
        "        Lst_y_fast[i].append(end_time - start_time)\n",
        "        if end_time - start_time > 10:\n",
        "            break\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        ind = i * 3 + j\n",
        "        axs[i, j].plot(Lst_x_lev[ind], Lst_y_lev[ind], label='Метод Маркварда-Левенберга')\n",
        "        axs[i, j].plot(Lst_x_fast[ind], Lst_y_fast[ind], label='Метод наискорейшего спуска')\n",
        "        axs[i, j].set_title(func_name_list[ind])\n",
        "        axs[i, j].set_xlabel('dimemsions')\n",
        "        axs[i, j].set_ylabel('time')\n",
        "        axs[i, j].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2eede59-0e71-4e0a-8fc6-9298465ff78a",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(21, 14))  # figsize=(ширина, высота)\n",
        "plt.tight_layout(pad=8.0)\n",
        "\n",
        "dim = 1\n",
        "steps = 100000\n",
        "prec_list = np.linspace(10 ** (-6), 10 ** (-5), 20)\n",
        "\n",
        "Lst_y_lev = []\n",
        "Lst_x_lev = []\n",
        "Lst_y_fast = []\n",
        "Lst_x_fast = []\n",
        "\n",
        "for i in range(number_of_func):\n",
        "    Lst_y_lev.append([])\n",
        "    Lst_y_fast.append([])\n",
        "    Lst_x_lev.append([])\n",
        "    Lst_x_fast.append([])\n",
        "    for prec in prec_list:\n",
        "        x0, param_list = param_gen[i](dim)\n",
        "        max_steps, eps = steps, prec\n",
        "        start_time = time.time()\n",
        "        result = levenberg_markvatd2(function_list[i], param_list, x0, max_steps, eps)\n",
        "        end_time = time.time()\n",
        "        Lst_x_lev[i].append(prec)\n",
        "        Lst_y_lev[i].append(end_time - start_time)\n",
        "        if end_time - start_time > 10:\n",
        "            break\n",
        "\n",
        "for i in range(number_of_func):\n",
        "    Lst_y_lev.append([])\n",
        "    Lst_y_fast.append([])\n",
        "    Lst_x_lev.append([])\n",
        "    Lst_x_fast.append([])\n",
        "    for prec in prec_list:\n",
        "        x0, param_list = param_gen[i](dim)\n",
        "        max_steps, eps = steps, prec\n",
        "        start_time = time.time()\n",
        "        result = the_fastest_descent(function_list[i], param_list, x0, max_steps, eps)\n",
        "        end_time = time.time()\n",
        "        Lst_x_fast[i].append(prec)\n",
        "        Lst_y_fast[i].append(end_time - start_time)\n",
        "        if end_time - start_time > 10:\n",
        "            break\n",
        "\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        ind = i * 3 + j\n",
        "        axs[i, j].plot(Lst_x_lev[ind], Lst_y_lev[ind], label='Метод Маркварда-Левенберга')\n",
        "        axs[i, j].plot(Lst_x_fast[ind], Lst_y_fast[ind], label='Метод наискорейшего спуска')\n",
        "        axs[i, j].set_title(func_name_list[ind])\n",
        "        axs[i, j].set_xlabel('accuracy')\n",
        "        axs[i, j].set_ylabel('time')\n",
        "        axs[i, j].legend()\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5783a64b-92f8-43ac-8c79-0300a7e89fcd",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(21, 14))  # figsize=(ширина, высота)\n",
        "plt.tight_layout(pad=8.0)\n",
        "\n",
        "prec = 1e-1\n",
        "steps = 1000\n",
        "\n",
        "Lst_y_lev = []\n",
        "Lst_y_fast = []\n",
        "\n",
        "for i in range(number_of_func):\n",
        "\n",
        "    Lst_y_lev.append([])\n",
        "    Lst_y_fast.append([])\n",
        "    dim = 10\n",
        "    for eps_golden in np.linspace(10 ** (-8), 10 ** (-7), 10):\n",
        "\n",
        "        start_time = time.time()\n",
        "        x0, param_list = param_gen[i](dim)\n",
        "        max_steps, eps = steps, prec\n",
        "        result = the_fastest_descent(function_list[i], param_list, x0, max_steps, eps)\n",
        "        end_time = time.time()\n",
        "        Lst_y_fast[i].append(end_time - start_time)\n",
        "\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        ind = i * 3 + j\n",
        "        axs[i, j].plot(golden_section_accuracies, Lst_y_fast[ind], label='Метод наискорейшего спуска')\n",
        "        axs[i, j].set_title(func_name_list[ind])\n",
        "        axs[i, j].set_xlabel('accuracy')\n",
        "        axs[i, j].set_ylabel('time')\n",
        "        axs[i, j].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba3737d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(21, 7))  # figsize=(ширина, высота)\n",
        "plt.tight_layout(pad=8.0)\n",
        "\n",
        "dim = 2\n",
        "steps = 100000\n",
        "prec = 1e-5\n",
        "dist_list = np.linspace(10 ** (0), 10 ** (1), 20)\n",
        "\n",
        "Lst_y_lev = []\n",
        "Lst_x_lev = []\n",
        "Lst_y_fast = []\n",
        "Lst_x_fast = []\n",
        "\n",
        "Lst_y_lev.append([])\n",
        "Lst_x_lev.append([])\n",
        "x_opt_list = [np.ones(dim), 0, np.ones(dim), (1 / np.arange(1, dim + 1)) * np.exp(-1), 0, 0]\n",
        "\n",
        "j = 0\n",
        "for i in [0, 2, 3]:\n",
        "    Lst_y_lev.append([])\n",
        "    Lst_x_lev.append([])\n",
        "\n",
        "    for dist in dist_list:\n",
        "        start_time = time.time()\n",
        "        _, param_list = param_gen[i](dim)\n",
        "        x0 = x_opt_list[i] + dist * np.ones(dim)\n",
        "        max_steps, eps = steps, prec\n",
        "        result = levenberg_markvatd2(function_list[i], param_list, x0, max_steps, eps)\n",
        "        end_time = time.time()\n",
        "        Lst_y_lev[j].append(end_time - start_time)\n",
        "        if end_time - start_time > 10:\n",
        "            break\n",
        "    j += 1\n",
        "\n",
        "j = 0\n",
        "for i in [0, 2, 3]:\n",
        "    Lst_y_fast.append([])\n",
        "    Lst_x_fast.append([])\n",
        "    for prec in prec_list:\n",
        "        start_time = time.time()\n",
        "        _, param_list = param_gen[i](dim)\n",
        "        x0 = x_opt_list[i] + dist * np.ones(dim)\n",
        "        start_time = time.time()\n",
        "        result = the_fastest_descent(function_list[i], param_list, x0, max_steps, eps)\n",
        "        end_time = time.time()\n",
        "        Lst_y_fast[j].append(end_time - start_time)\n",
        "        if end_time - start_time > 10:\n",
        "            break\n",
        "    j += 1\n",
        "\n",
        "\n",
        "for j in range(3):\n",
        "    axs[j].plot(dist_list, Lst_y_lev[j], label='Метод Маркварда-Левенберга')\n",
        "    axs[j].plot(dist_list, Lst_y_fast[j], label='Метод наискорейшего спуска')\n",
        "    axs[j].set_title(func_name_list[j])\n",
        "    axs[j].set_xlabel('dist')\n",
        "    axs[j].set_ylabel('time')\n",
        "    axs[j].legend()\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
